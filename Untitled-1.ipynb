{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !pip install -U scikit_learn catboost pandas 'numpy<=1.23.0' seaborn matplotlib"]},{"cell_type":"markdown","metadata":{},"source":["# My entry in the Spaceship Titanic Competition\n","\n","What I've tried in previous versions of the notebook:\n","\n","**Classifiers**\n","\n","- LogisticRegression\n","- RandomForestClassifier\n","- GradientBoostingClassifier\n","- SVC\n","- SGDClassifier\n","- KNeighborsClassifier\n","\n","**Preprocessing**\n","\n","- Removal of outliers using IsolationForest, followed by oversampling with SMOTE.\n","\n","**CatBoost**\n","\n","- Running on GPU achieves lower accuracy (algorithm has less precision)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T01:21:57.307004Z","iopub.status.busy":"2023-07-05T01:21:57.306512Z","iopub.status.idle":"2023-07-05T01:22:01.514955Z","shell.execute_reply":"2023-07-05T01:22:01.513420Z","shell.execute_reply.started":"2023-07-05T01:21:57.306960Z"},"id":"mmwBzpblmnjH","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pathlib as pl\n","from catboost import CatBoostClassifier\n","from sklearn.impute import KNNImputer\n","from sklearn.inspection import permutation_importance\n","import optuna"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6sHFpppPmnjJ"},"source":["# Load the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T01:37:52.376635Z","iopub.status.busy":"2023-07-05T01:37:52.376180Z","iopub.status.idle":"2023-07-05T01:37:52.428129Z","shell.execute_reply":"2023-07-05T01:37:52.426909Z","shell.execute_reply.started":"2023-07-05T01:37:52.376594Z"},"id":"c1P3Y3a7mnjL","trusted":true},"outputs":[],"source":["# Load a dataset into a Pandas Dataframe\n","data_path = pl.Path(\"/kaggle/input/spaceship-titanic/\")\n","if not data_path.exists():\n","    data_path = pl.Path(\"data\")\n","df = pd.read_csv(data_path / \"train.csv\")\n","df[[\"HomePlanet\", \"Destination\"]] = df[[\"HomePlanet\", \"Destination\"]].astype(\"category\")\n","# df[\"VIP\"] = df[\"VIP\"].astype(bool)\n","print(\"Full train dataset shape is {}\".format(df.shape))\n","label = \"Transported\"\n","df.head(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Exploratory data analysis\n","\n","Before starting, there are some columns that can be further broken down into more data, which will make our analysis more complete.\n","\n","After we impute missing data in the original columns, we'll have to generate these surrogate columns again."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_l1_features(df):\n","    df = df.copy()\n","    df[[\"Room\", \"PassengerGroupId\"]] = df[\"PassengerId\"].str.split(\"_\", expand=True).astype(int)\n","\n","    No_People_In_PassengerGroup = (\n","        df.groupby(\"Room\").aggregate({\"PassengerId\": \"size\"}).reset_index()\n","    )\n","    No_People_In_PassengerGroup = No_People_In_PassengerGroup.rename(\n","        columns={\"PassengerId\": \"NoInPassengerGroup\"}\n","    )\n","    df = df.merge(\n","        No_People_In_PassengerGroup[[\"Room\"]],\n","        how=\"left\",\n","        on=[\"Room\"],\n","    )\n","\n","    # Split Cabin into Deck, Number and Side features\n","    df[[\"CabinDeck\", \"CabinNum\", \"CabinSide\"]] = df[\"Cabin\"].str.split(\"/\", expand=True)\n","\n","    df[[\"FirstName\", \"FamilyName\"]] = df[\"Name\"].str.split(\" \", expand=True)\n","    # Create NoRelatives feature\n","    NoRelatives = df.groupby(\"FamilyName\")[\"PassengerId\"].count().reset_index()\n","    NoRelatives = NoRelatives.rename(columns={\"PassengerId\": \"NoRelatives\"})\n","\n","    df = df.merge(\n","        NoRelatives[[\"FamilyName\", \"NoRelatives\"]], how=\"left\", on=[\"FamilyName\"]\n","    )\n","\n","    # Categorical encoding, drop redundant columns\n","    df = pd.get_dummies(\n","        df,\n","        columns=[\"CabinSide\"],\n","        drop_first=True,\n","    )\n","\n","    # Ordinal Encoding\n","    df[[\"CabinDeck\", \"PassengerGroupId\"]] = df[\n","        [\"CabinDeck\", \"PassengerGroupId\"]\n","    ].astype(\"category\")\n","\n","    # df3.CabinDeck = df3.CabinDeck.astype(\"category\")\n","    # df3.DeckPosition = df3.DeckPosition.astype(\"category\")\n","    # df3.CabinNum = df3.CabinNum.astype(int)\n","\n","    df.drop(columns=[\"PassengerId\", \"Cabin\", \"Name\"], inplace=True)\n","\n","    return df\n","\n","\n","df_eda = extract_l1_features(df)\n","df_eda.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Helper functions to plot univariate and bivariate charts for categorical and numeric data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T01:38:04.833415Z","iopub.status.busy":"2023-07-05T01:38:04.832970Z","iopub.status.idle":"2023-07-05T01:38:05.978456Z","shell.execute_reply":"2023-07-05T01:38:05.977206Z","shell.execute_reply.started":"2023-07-05T01:38:04.833377Z"},"id":"DcaGweARmnjP","trusted":true},"outputs":[],"source":["def config_axes(list_df_cols, dependent: str | None = None, n_per_row=None):\n","    if dependent is not None and dependent in list_df_cols:\n","        list_df_cols.remove(dependent)\n","\n","    if n_per_row:\n","        nrows = len(list_df_cols)\n","        ncols = n_per_row\n","    else:\n","        sqrt_n_cols = np.sqrt(len(list_df_cols))\n","        # nrows = int(np.floor(sqrt_n_cols))\n","        nrows = ncols = int(np.ceil(sqrt_n_cols))\n","\n","    figsize = (ncols * 5, nrows * 4)\n","    _, axes = plt.subplots(nrows, ncols, figsize=figsize)\n","    return axes\n","\n","\n","def plot_cat_cols(df: pd.DataFrame, dependent: str | None = None):\n","    list_df_cols = sorted(\n","        list(df.select_dtypes([\"object\", \"category\", \"bool\"]).columns)\n","    )\n","    if dependent is not None and dependent in list_df_cols:\n","        list_df_cols.remove(dependent)\n","\n","    axes = config_axes(list_df_cols, dependent).flat\n","    axes = iter(axes)\n","\n","    for col in list_df_cols:\n","        ax = next(axes)\n","        if dependent is None:\n","            sns.countplot(data=df, x=col, order=df[col].sort_values().unique(), ax=ax)\n","        else:\n","            sns.barplot(\n","                data=df,\n","                x=col,\n","                y=dependent,\n","                order=df[col].sort_values().unique(),\n","                orient=\"v\",\n","                ax=ax,\n","            )\n","        ax.bar_label(ax.containers[0])\n","\n","    plt.tight_layout()\n","\n","\n","def plot_numeric_cols(df: pd.DataFrame, dependent: str | None = None):\n","    list_df_cols = list(df.select_dtypes(np.number).columns)\n","\n","    axes = iter(config_axes(list_df_cols, dependent, 2).flat)\n","    for col in list_df_cols:\n","        if dependent is None:\n","            sns.histplot(\n","                data=df,\n","                color=\"b\",\n","                x=col,\n","                ax=next(axes),\n","            )\n","            sns.boxplot(\n","                data=df,\n","                color=\"b\",\n","                y=col,\n","                ax=next(axes),\n","            )\n","        else:\n","            sns.violinplot(\n","                data=df,\n","                x=dependent,\n","                y=col,\n","                ax=next(axes),\n","            )\n","            sns.boxplot(\n","                data=df,\n","                x=dependent,\n","                y=col,\n","                ax=next(axes),\n","            )\n","\n","    plt.tight_layout()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Univariate analysis of categorical variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# remove columns with too many values\n","plot_cat_cols(\n","    df_eda.drop(\n","        columns=[\"FirstName\", \"FamilyName\", \"CabinNum\"]\n","    )\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Conclusions\n","\n","- Cabin decks F and G have a lot more people than the other ones, it may be valuable to see if other features explain this disparity. Maybe rich and poor people travel separately, like in the original Titanic?\n","- Cabin deck T has only 5 people, who are they?\n","- Most people are going to TRAPPIST-1e.\n","- Most people come from Earth.\n","- The dataset is balanced: roughly the same amount of transported and non-transported people in the ship.\n","- PassengerGroupId has logarithmic behavior, but this is just the nature of the data (all groups have at least one person with group ID 1 and larger groups are more rare)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LRO2hJlNmnjP"},"source":["## Univariate analysis of numerical variables"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T01:38:06.062096Z","iopub.status.busy":"2023-07-05T01:38:06.061299Z","iopub.status.idle":"2023-07-05T01:38:07.921281Z","shell.execute_reply":"2023-07-05T01:38:07.920014Z","shell.execute_reply.started":"2023-07-05T01:38:06.062046Z"},"id":"lafxj4fkmnjQ","trusted":true},"outputs":[],"source":["plot_numeric_cols(df_eda)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Conclusions\n","\n","- Age is not totally normally distributed. There are more young people than old.\n","- Most people spend very little to no money. Are there lots of poor people or is there some explanation to this?"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Bivariate analysis of categorical variables against dependent variable"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# remove columns with too many values\n","plot_cat_cols(\n","    df_eda.drop(\n","        columns=[\"FirstName\", \"FamilyName\", \"CabinNum\"]\n","    ),\n","    dependent=label,\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Conclusions\n","\n","- Cabin sides B and C have more transported people (proportionally, inside the group). \n","- Even though we have more people coming from Earth and going to TRAPPIST-1e, these are the sources of the fewest transported people.\n","- People in cryogenic sleep have been transported much more than awake people."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Bivariate analysis of numerical variables against dependent variable"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_numeric_cols(df_eda, dependent=label)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Conclusions\n","\n","- Age has no bearing on who gets transported.\n","- For some reason, people who get transported spend **less** money on room service, Spa and VR deck."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Bivariate analysis, misc"]},{"cell_type":"markdown","metadata":{},"source":["\n","### CryoSleep\n","\n","There could be something going on with lots of people in cryogenic sleep being transported and people who spend less in certain activities also being transported. Let's check out the relationship between CryoSleep and the numeric variables. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_numeric_cols(df_eda, dependent=\"CryoSleep\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Conclusions\n","\n","- Age has no bearing on who gets turned into a popsicle.\n","- People in cryogenic sleep spend no money **at all**. but because of that, we don't know if they are wealthy or not."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Passenger spending\n","\n","Let's also look at passenger spending by age. Maybe old people are richer and spend more, while kids spend less.\n","\n","For that, we'll split people by their ages into categories."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_eda[\"AgeCat\"] = pd.cut(\n","    df_eda.Age,\n","    bins=[0, 4, 12, 17, 25, 34, 55, 80],\n","    labels=[\"0 - 4\", \"5 - 12\", \"13 - 17\", \"18 - 25\", \"26 - 34\", \"35 - 55\", \"56 - 80\"],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_numeric_cols(df_eda.drop(columns=\"Age\"), dependent=\"AgeCat\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Conclusions\n","\n","- Kids also do no spend any money."]},{"cell_type":"markdown","metadata":{},"source":["### VIP stats by age\n","\n","A little bird told me to take a look at this one..."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.crosstab(df_eda['AgeCat'],df_eda['VIP'])"]},{"cell_type":"markdown","metadata":{},"source":["#### Conclusions\n","\n","- People under 18 are not VIPs."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del df_eda['AgeCat']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### TODO\n","\n","- Visualize spending, cryo sleep, home planet and destination by deck.\n","- Analyze the compositions of cabins B/C (the ones with most transported) and F/G (the ones with the most people) against CryoSleep and spending."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Classification\n","\n","To create our classifier, we'll need to:\n","\n","- impute missing values\n","- encode features according to our different classifier needs\n","- test a few classifiers (already done, see the introduction)\n","\n","## Dealing with missing values\n","\n","In this section, we'll deal with the missing data in the original dataset, without the generated features. After inserting as much missing data as we can, we'll create those columns again."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.isna().sum()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's use our knowledge that kids and sleepers don't spend and fill those missing values in a more informed way. Let's also set everyone under 18 as non-VIPs."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fill_nans_by_age_and_cryosleep(df):\n","    df = df.copy()\n","    non_spenders = (df[\"Age\"] < 13) | (df[\"CryoSleep\"] == True)\n","    df.loc[non_spenders, \"RoomService\"] = 0\n","    df.loc[non_spenders, \"FoodCourt\"] = 0\n","    df.loc[non_spenders, \"ShoppingMall\"] = 0\n","    df.loc[non_spenders, \"Spa\"] = 0\n","    df.loc[non_spenders, \"VRDeck\"] = 0\n","    non_spenders_2 = (\n","        (df[[\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].sum(1) == 0)\n","        & (df[\"CryoSleep\"].isna())\n","        & (df[\"Age\"] >= 13)\n","    )\n","    df.loc[non_spenders_2, \"CryoSleep\"] = True\n","\n","    df.loc[df[\"Age\"] < 18, \"VIP\"] = False\n","\n","    return df\n","\n","\n","df_clf = fill_nans_by_age_and_cryosleep(df)\n","df_clf.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generalize_by_room(df: pd.DataFrame):\n","    df = df.copy()\n","\n","    generalizable_cols = [\"VIP\", \"Cabin\", \"HomePlanet\", \"Destination\"]\n","\n","    df.loc[:, [\"Room\"]] = df.PassengerId.apply(lambda x: x[0:4])\n","\n","    for col in generalizable_cols:\n","        guide = df.loc[:, [\"Room\", col]].dropna().drop_duplicates(\"Room\")\n","        df = pd.merge(df, guide, how=\"left\", on=\"Room\", suffixes=(\"\", \"_y\"))\n","        # guide = df.loc[:, [\"Room\", col]].dropna().drop_duplicates(\"Room\")\n","        df.loc[:, [col]] = df.apply(\n","            lambda x: x[col + \"_y\"] if pd.isna(x[col]) else x, axis=1\n","        )\n","    df.drop(columns=[\"Room\"] + [col + \"_y\" for col in generalizable_cols], inplace=True)\n","    return df\n","\n","\n","df_clf = generalize_by_room(df_clf)\n","df_clf.isna().sum()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The rest of categorical variables will be filled with the mode."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fill_with_mode(df: pd.DataFrame, cols: None | list[str] = None) -> pd.DataFrame:\n","    if cols is None:\n","        # Clever way to list categorical variables with missing values\n","        cols = list(\n","            (df.select_dtypes([\"object\", \"category\", \"bool\"]).isna().sum() > 0).index\n","        )\n","\n","    for col in cols:\n","        df[col] = df[col].fillna(df[col].mode()[0])\n","\n","    return df\n","\n","\n","df_clf = fill_with_mode(df_clf)\n","df_clf.isna().sum()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Rows with missing numeric values will be filled with sklearn Iterative Imputer. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fill_missing_numeric(df: pd.DataFrame) -> pd.DataFrame:\n","    df = df.copy()\n","    list_missing_numeric_col = list(\n","        (df.select_dtypes(np.number).isna().sum() > 0).index\n","    )\n","    list_numeric_col = list(df.select_dtypes(np.number))\n","    imputed_numeric_cols = KNNImputer().fit_transform(df[list_numeric_col])\n","    imputed_numeric_cols = pd.DataFrame(imputed_numeric_cols, columns=list_numeric_col)\n","    imputed_numeric_cols = imputed_numeric_cols[list_missing_numeric_col]\n","    df[list_missing_numeric_col] = imputed_numeric_cols\n","\n","    return df\n","\n","\n","df_clf = fill_missing_numeric(df_clf)\n","df_clf.isna().sum()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Clip outliers in numerical columns on the 99% quantile."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def clipping_quantile(df, quantile_values = None, quantile = 0.99):\n","    df = df.copy()\n","    list_numeric_col = list(df.select_dtypes(np.number))\n","    if quantile_values is None:\n","        quantile_values = df[list_numeric_col].quantile(quantile)\n","    for num_column in list_numeric_col:\n","        num_values = df[num_column].values\n","        threshold = quantile_values[num_column]\n","        num_values = np.where(num_values > threshold, threshold, num_values)\n","        df[num_column] = num_values\n","    return df      \n","    \n","df_clf = clipping_quantile(df_clf, None, 0.99)\n","# plot_numeric_cols(df_clf)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now we'll create some additional features based on our previous findings."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_l2_features(df):\n","    df = df.copy()\n","    df[\"DeckPosition\"] = (\n","        df[\"CabinDeck\"]\n","        .apply(lambda deck: \"Lower\" if deck in (\"A\", \"B\", \"C\", \"D\") else \"Higher\")\n","        .astype(\"category\")\n","    )\n","    df[\"Regular\"] = df[\"FoodCourt\"] + df[\"ShoppingMall\"]\n","    df[\"Luxury\"] = df[\"RoomService\"] + df[\"Spa\"] + df[\"VRDeck\"]\n","    df[\"Expenses\"] = df[[\"FoodCourt\", \"ShoppingMall\", \"RoomService\", \"Spa\", \"VRDeck\"]].sum(1)\n","    # Create FamilySizeCat feature\n","    df[\"FamilySizeCat\"] = pd.cut(df.NoRelatives, bins=[0, 2, 5, 10, 300], labels=False)\n","    return df\n","\n","\n","df_clf = extract_l1_features(df_clf)\n","df_clf = extract_l2_features(df_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["irrelevant_columns = [\"FirstName\", \"FamilyName\", \"Room\"]\n","df_clf.CabinNum = df_clf.CabinNum.astype(int)\n","df_clf.drop(columns=irrelevant_columns,inplace=True)\n","df_clf.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sy81fpfxmnjY"},"source":["## Feature selection\n","\n","We will train the classifier with some default hyperparameters and see which features are the most important.\n","\n","The best features and classifiers are the ones that achieve the highest classification accuracy, which is the metric chosen by the Kaggle competition."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = df_clf.copy()\n","X.drop(\"Transported\", axis=1, inplace=True)\n","# X = pd.get_dummies(X, drop_first=True)\n","y = df_clf['Transported'].copy().astype(int)\n","X.info()"]},{"cell_type":"markdown","metadata":{},"source":["Let's check the baseline accuracy of the model with all features."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T01:58:53.776007Z","iopub.status.busy":"2023-07-05T01:58:53.775143Z","iopub.status.idle":"2023-07-05T01:58:53.800288Z","shell.execute_reply":"2023-07-05T01:58:53.798790Z","shell.execute_reply.started":"2023-07-05T01:58:53.775946Z"},"id":"j7-gFVDNmnjZ","trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold, cross_val_score\n","\n","cat_features = list(X.select_dtypes([\"object\", \"category\"]))\n","\n","clf = CatBoostClassifier(\n","    cat_features=cat_features, eval_metric=\"Accuracy\", verbose=False\n",")\n","cv_scores = cross_val_score(clf, X, y, cv=StratifiedKFold(n_splits=6),scoring='accuracy')\n","print(cv_scores, cv_scores.mean())"]},{"cell_type":"markdown","metadata":{},"source":["Fit the model with all features and check feature importances."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf.fit(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.barh(clf.feature_names_, clf.feature_importances_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["importances = permutation_importance(clf, X, y, scoring=\"accuracy\")\n","names, imps, impsstd = zip(\n","    *sorted(\n","        zip(\n","            clf.feature_names_,\n","            importances[\"importances_mean\"],\n","            importances[\"importances_std\"],\n","        ),\n","        key=lambda x: -x[1],\n","    )\n",")\n","plt.barh(names, imps, xerr=impsstd)\n","print(names)"]},{"cell_type":"markdown","metadata":{},"source":["We can remove the less imporant features from the training data and see if this improves performance in the validation set."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X.drop(\n","    columns=[\n","        \"Spa\",\n","        \"ShoppingMall\",\n","        \"VRDeck\",\n","        \"NoRelatives\",\n","        \"RoomService\",\n","        \"DeckPosition\",\n","        \"PassengerGroupId\",\n","        \"FamilySizeCat\",\n","        \"VIP\",\n","    ],\n","    inplace=True,errors=\"ignore\"\n",")\n","cat_features = list(X.select_dtypes([\"object\", \"category\"]))\n","clf = CatBoostClassifier(\n","    cat_features=cat_features, eval_metric=\"Accuracy\", verbose=False\n",")\n","cv_scores = cross_val_score(\n","    clf, X, y, cv=StratifiedKFold(n_splits=6), scoring=\"accuracy\"\n",")\n","print(cv_scores, cv_scores.mean())"]},{"cell_type":"markdown","metadata":{},"source":["In my personal case, CV performance went *down* when removingh less important features but, when I submitted the output, I got better results. Go figure."]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameter search\n","\n","Let's use Optuna to find a good set of hyperparameters for the model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# define objective function for hyperparameter optimization using optuna\n","def objective(trial):\n","    # define hyperparameters to optimize for\n","    params = {\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n","        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.005, 1),\n","        \"subsample\": trial.suggest_uniform(\"subsample\", 0.1, 1),\n","        \"l2_leaf_reg\": trial.suggest_uniform(\"l2_leaf_reg\", 0, 0.001),\n","    }\n","    cat_features = list(X.select_dtypes([\"object\", \"category\"]))\n","    model = CatBoostClassifier(\n","        **params, cat_features=cat_features, verbose=False, random_state=42\n","    )\n","\n","    # evaluate model using cross-validation\n","    score = cross_val_score(\n","        model, X, y, cv=StratifiedKFold(n_splits=5), scoring=\"accuracy\"\n","    ).mean()\n","\n","    return score\n","\n","\n","# run hyperparameter optimization with optuna\n","study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=50)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DAtAR0vkmnje"},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_features(df: pd.DataFrame) -> pd.DataFrame:\n","    df = df.copy()\n","    df = fill_nans_by_age_and_cryosleep(df)\n","    df = fill_with_mode(df)\n","    df = fill_missing_numeric(df)\n","    df = extract_l1_features(df)\n","    df = extract_l2_features(df)\n","    df = clipping_quantile(df, None, 0.99)\n","    irrelevant_columns = [\n","        \"Spa\",\n","        \"ShoppingMall\",\n","        \"VRDeck\",\n","        \"NoRelatives\",\n","        \"RoomService\",\n","        \"DeckPosition\",\n","        \"PassengerGroupId\",\n","        \"FamilySizeCat\",\n","        \"VIP\",\n","        \"FirstName\",\n","        \"FamilyName\",\n","        \"Room\",\n","    ]\n","    df.CabinNum = df.CabinNum.astype(int)\n","    df.drop(columns=irrelevant_columns, inplace=True)\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHBRzBD9mnjf","trusted":true},"outputs":[],"source":["# Load the test dataset\n","test_df = pd.read_csv(data_path / \"test.csv\")\n","submission_id = test_df.PassengerId\n","test_df = process_features(test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the predictions for testdata\n","predictions = clf.predict(test_df)\n","n_predictions = (predictions > 0.5).astype(bool)\n","output = pd.DataFrame(\n","    {\"PassengerId\": submission_id, \"Transported\": n_predictions.squeeze()}\n",")\n","output.to_csv(\"submission.csv\", index=False)\n","output.head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
